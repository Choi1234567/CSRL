{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from environments.education.DKT_model import get_custom_DKT_model\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data_folder = '../education/saved_data'\n",
    "train_file_name = 'DKT_data/builder_train.csv'\n",
    "test_file_name = 'DKT_data/builder_test.csv'\n",
    "all_problems_file_name = f'{saved_data_folder}/all_problems.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_problems = []\n",
    "\n",
    "with open(all_problems_file_name, 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        problem = line[:-1] # remove linebreak which is the last character of the string\n",
    "        all_problems.append(int(problem))\n",
    "\n",
    "n_problems = len(all_problems)\n",
    "n_features = 2*n_problems\n",
    "batch_size = 100 # Batch size\n",
    "val_fraction = 0.2\n",
    "MASK = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_to_df(file_name, all_problems):\n",
    "    line_num = 0\n",
    "    student_number = 0\n",
    "    skip_student = False\n",
    "\n",
    "    students_ids = []\n",
    "    students_problems = []\n",
    "    students_answers = []\n",
    "\n",
    "    with open(file_name, 'r', newline = '') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            if line_num % 3 == 0:\n",
    "                num_student_problems = int(row[0])\n",
    "                if num_student_problems > 1:\n",
    "                    skip_student = False\n",
    "                else:\n",
    "                    skip_student = True\n",
    "            if line_num % 3 == 1 and not skip_student:\n",
    "                for i in range(num_student_problems):\n",
    "                    students_ids.append(student_number)\n",
    "                    problem = int(row[i])\n",
    "                    problem_id = all_problems.index(problem)\n",
    "                    students_problems.append(problem_id)\n",
    "\n",
    "            if line_num % 3 == 2 and not skip_student:\n",
    "                for i in range(num_student_problems):\n",
    "                    students_answers.append(int(row[i]))\n",
    "                student_number += 1\n",
    "            line_num += 1\n",
    "    data_dict = {'student_id': students_ids, 'problem_id': students_problems, 'correctness': students_answers}\n",
    "    data_df = pd.DataFrame(data_dict)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_df(df, n_problems, n_features, batch_size=32, shuffle=True):\n",
    "    df['problem_answer'] = df['problem_id'] *2 + df['correctness'] #combine problem id and correctness\n",
    "    \n",
    "    seq = df.groupby('student_id').apply(\n",
    "        lambda r: (\n",
    "            r['problem_answer'].values[:-1],\n",
    "            r['problem_id'].values[1:],\n",
    "            r['correctness'].values[1:],\n",
    "        )\n",
    "    )\n",
    "    nb_users = len(seq)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator=lambda: seq,\n",
    "        output_types=(tf.int32, tf.int32, tf.float32)\n",
    "    )\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=nb_users)\n",
    "\n",
    "    features_depth = n_problems*2\n",
    "    skill_depth = n_problems\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda feat, skill, label: (\n",
    "            tf.one_hot(feat, depth=features_depth),\n",
    "            tf.concat( values=[tf.one_hot(skill, depth=skill_depth),tf.expand_dims(label, -1)],axis=-1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dataset = dataset.padded_batch(\n",
    "        batch_size=batch_size,\n",
    "        padding_values=(MASK, MASK),\n",
    "        padded_shapes=([None, None], [None, None]),\n",
    "        drop_remainder=True\n",
    "    )\n",
    "\n",
    "    length = nb_users // batch_size\n",
    "    return dataset, nb_users, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset, total_length, val_fraction):\n",
    "    train_length = int(total_length*(1-val_fraction))\n",
    "    train_set = dataset.take(train_length)\n",
    "    val_set = dataset.skip(train_length)\n",
    "    return train_set, val_set, train_length, total_length-train_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_df = load_file_to_df(train_file_name, all_problems)\n",
    "test_data_df = load_file_to_df(test_file_name, all_problems)\n",
    "n_features = len(all_problems)*2\n",
    "n_problems = len(all_problems)\n",
    "\n",
    "all_train_dataset, all_train_total, all_train_batches = create_dataset_from_df(all_train_data_df, n_problems, n_features, batch_size = batch_size)\n",
    "test_dataset, test_total, test_batches  = create_dataset_from_df(test_data_df, n_problems, n_features, batch_size = batch_size)\n",
    "\n",
    "train_dataset, val_dataset, train_batches, val_batches = train_val_split(all_train_dataset, all_train_batches, val_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set size: %d\" % int(all_train_total*(1-val_fraction)))\n",
    "print(\"Validation set size: %d\" % int(all_train_total*(val_fraction)))\n",
    "print(\"Testing set size: %d\" % (test_total))\n",
    "print(\"Number of skills: %d\" % n_problems)\n",
    "print(\"Total number of students: %d\" % (all_train_total + test_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Student Model used in experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = get_custom_DKT_model(saved_data_folder = saved_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_folder = 'model_weights'\n",
    "save_model_name = 'model_weights_test'\n",
    "try:\n",
    "    os.mkdir(save_model_folder)\n",
    "except:\n",
    "    pass\n",
    "save_model_file = f\"{save_model_folder}/{save_model_name}\"\n",
    "epochs = 20 # Number of epochs to train\n",
    "verbose = 1\n",
    "shuffle = True\n",
    "log_dir = \"logs\" # Path to save the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[ \n",
    "    tf.keras.callbacks.CSVLogger(f\"{log_dir}/train.log\"),\n",
    "    tf.keras.callbacks.ModelCheckpoint(save_model_file,\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=True),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "student_model.train(train_dataset, val_dataset, epochs, verbose, callbacks, shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.evaluate(test_dataset, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS_DDQN",
   "language": "python",
   "name": "cs_ddqn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
